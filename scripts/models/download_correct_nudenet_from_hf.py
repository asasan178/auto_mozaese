#!/usr/bin/env python3
"""
HuggingFace„Åã„ÇâÊ≠£„Åó„ÅÑNudeNet„É¢„Éá„É´„Éï„Ç°„Ç§„É´„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åô„Çã„Çπ„ÇØ„É™„Éó„Éà
"""

import os
import requests
from pathlib import Path

def download_file_with_progress(url, destination):
    """„Éó„É≠„Ç∞„É¨„Çπ„Éê„Éº‰ªò„Åç„Åß„Éï„Ç°„Ç§„É´„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ"""
    print(f"„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÈñãÂßã: {url}")
    
    response = requests.get(url, stream=True)
    response.raise_for_status()
    
    total_size = int(response.headers.get('content-length', 0))
    downloaded_size = 0
    
    with open(destination, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                f.write(chunk)
                downloaded_size += len(chunk)
                
                # „Éó„É≠„Ç∞„É¨„ÇπË°®Á§∫
                if total_size > 0:
                    progress = (downloaded_size / total_size) * 100
                    print(f"\rÈÄ≤Ë°åÁä∂Ê≥Å: {progress:.1f}% ({downloaded_size/1024/1024:.1f}MB/{total_size/1024/1024:.1f}MB)", end='')
    
    print()  # ÊîπË°å
    file_size = os.path.getsize(destination)
    print(f"„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÂÆå‰∫Ü: {destination} ({file_size/1024/1024:.2f} MB)")
    return file_size

def main():
    # nudenet_models„Éá„Ç£„É¨„ÇØ„Éà„É™„ÇíÊ∫ñÂÇô
    models_dir = Path("nudenet_models")
    models_dir.mkdir(exist_ok=True)
    
    # HuggingFace„ÅÆÊ≠£„Åó„ÅÑNudeNet„É¢„Éá„É´URL
    base_url = "https://huggingface.co/gqfwqgw/NudeNet_classifier_model/resolve/d9606abb0e0260c99765e09360df4e26d81ee794"
    
    models_to_download = [
        {
            "filename": "classifier_model.onnx",
            "url": f"{base_url}/classifier_model.onnx",
            "expected_size": 83.6 * 1024 * 1024  # 83.6MB
        },
        {
            "filename": "detector_v2_default_checkpoint.onnx", 
            "url": f"{base_url}/detector_v2_default_checkpoint.onnx",
            "expected_size": 147 * 1024 * 1024  # 147MB
        }
    ]
    
    print("=== Ê≠£„Åó„ÅÑNudeNet„É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ ===")
    
    for model in models_to_download:
        destination = models_dir / model["filename"]
        
        # Êó¢Â≠ò„ÅÆ„Éï„Ç°„Ç§„É´„Çí„ÉÅ„Çß„ÉÉ„ÇØ
        if destination.exists():
            current_size = destination.stat().st_size
            expected_size = model["expected_size"]
            
            if current_size >= expected_size * 0.9:  # ÊúüÂæÖ„Çµ„Ç§„Ç∫„ÅÆ90%‰ª•‰∏ä„Å™„ÇâÊ≠£Â∏∏„Å®„Åø„Å™„Åô
                print(f"‚úÖ {model['filename']} „ÅØÊó¢„Å´Ê≠£„Åó„ÅÑ„Çµ„Ç§„Ç∫„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊ∏à„Åø ({current_size/1024/1024:.2f} MB)")
                continue
            else:
                print(f"üóëÔ∏è Â∞è„Åï„Åô„Åé„Çã„Éï„Ç°„Ç§„É´„ÇíÂâäÈô§: {destination} ({current_size} bytes)")
                destination.unlink()
        
        try:
            actual_size = download_file_with_progress(model["url"], destination)
            
            if actual_size >= model["expected_size"] * 0.9:
                print(f"‚úÖ {model['filename']} „ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÅåÊàêÂäü„Åó„Åæ„Åó„Åü")
            else:
                print(f"‚ö†Ô∏è Ë≠¶Âëä: {model['filename']} „ÅÆ„Çµ„Ç§„Ç∫„ÅåÊúüÂæÖÂÄ§„Çà„ÇäÂ∞è„Åï„ÅÑ„Åß„Åô")
                
        except Exception as e:
            print(f"‚ùå {model['filename']} „ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Å´Â§±Êïó: {e}")
    
    # ÊúÄÁµÇÁ¢∫Ë™ç
    print("\n=== „É¢„Éá„É´„Éï„Ç°„Ç§„É´ÊúÄÁµÇÁ¢∫Ë™ç ===")
    for file in models_dir.glob("*.onnx"):
        size = file.stat().st_size
        status = "‚úÖ" if size > 10 * 1024 * 1024 else "‚ö†Ô∏è"  # 10MB‰ª•‰∏ä„ÅßÊ≠£Â∏∏
        print(f"{status} {file.name}: {size/1024/1024:.2f} MB")

if __name__ == "__main__":
    main() 