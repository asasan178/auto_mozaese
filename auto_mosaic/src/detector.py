"""
YOLO-based genital detection for anime/illustration images
"""

from typing import List, Optional, Tuple, Dict, Any
from pathlib import Path
import time

# ÂãïÁöÑ„Ç§„É≥„Éù„Éº„ÉàÁî®„ÅÆÈÅÖÂª∂„É≠„Éº„ÉÄ„Éº
from auto_mosaic.src.lazy_loader import load_numpy, load_torch, load_cv2, load_ultralytics

# ÂãïÁöÑ„Ç§„É≥„Éù„Éº„Éà„Åß„É©„Ç§„Éñ„É©„É™„Çí„É≠„Éº„Éâ
def _load_dependencies():
    """ÂøÖË¶Å„Å™‰æùÂ≠òÈñ¢‰øÇ„ÇíÂãïÁöÑ„Å´„É≠„Éº„Éâ"""
    global np, torch, cv2, YOLO
    
    np = load_numpy()
    torch = load_torch()
    cv2 = load_cv2()
    
    # PyTorch 2.6 compatibility: Allow loading of older model files
    import torch.serialization

    # Set default weights_only behavior to False
    try:
        torch.serialization._weights_only_pickle_default = False
    except AttributeError:
        pass

    # Global override for torch.load to force weights_only=False
    _original_torch_load = torch.load
    def _patched_torch_load(f, *args, **kwargs):
        kwargs['weights_only'] = False  # Force weights_only=False for all loads
        return _original_torch_load(f, *args, **kwargs)
    torch.load = _patched_torch_load

    # ultralytics „ÇíÂãïÁöÑ„Å´„É≠„Éº„Éâ
    ultralytics = load_ultralytics()
    
    # Add all necessary safe globals for ultralytics
    try:
        from ultralytics.nn.tasks import SegmentationModel, DetectionModel
        from ultralytics.nn.modules import Conv, Bottleneck, C2f, SPPF
        torch.serialization.add_safe_globals([
            SegmentationModel, DetectionModel, Conv, Bottleneck, C2f, SPPF
        ])
    except ImportError:
        pass
    except Exception:
        pass

    # Additional fallback for complete compatibility
    import warnings
    warnings.filterwarnings("ignore", message="Weights only load failed.*")
    warnings.filterwarnings("ignore", message=".*WeightsUnpickler.*")

    try:
        from ultralytics import YOLO as _YOLO
        YOLO = _YOLO
    except (ImportError, AttributeError):
        YOLO = None

# „Ç∞„É≠„Éº„Éê„É´Â§âÊï∞„ÅÆÂàùÊúüÂåñ
np = None
torch = None
cv2 = None
YOLO = None

# ‰æùÂ≠òÈñ¢‰øÇ„Åå„É≠„Éº„Éâ„Åï„Çå„Å¶„ÅÑ„Çã„Åã„ÉÅ„Çß„ÉÉ„ÇØ„Åô„ÇãÈñ¢Êï∞
def _ensure_dependencies_loaded():
    """‰æùÂ≠òÈñ¢‰øÇ„Åå„É≠„Éº„Éâ„Åï„Çå„Å¶„ÅÑ„Çã„Åì„Å®„ÇíÁ¢∫Ë™ç"""
    global np, torch, cv2, YOLO
    if np is None or torch is None or cv2 is None or YOLO is None:
        _load_dependencies()

from auto_mosaic.src.utils import logger, BBox, BBoxWithClass, expand_bboxes, get_recommended_device
from auto_mosaic.src.downloader import downloader

class GenitalDetector:
    """YOLO-based genital region detector"""
    
    def __init__(self, model_path: str, device: str = "auto", lite: bool = False):
        """
        Initialize detector
        
        Args:
            model_path: Path to YOLO model
            device: Device for inference ('cpu', 'cuda', or 'auto')
            lite: Whether using lite model (True = specialized genital model, False = general person model)
        """
        # ‰æùÂ≠òÈñ¢‰øÇ„ÇíÊúÄÂàù„Å´„É≠„Éº„Éâ
        _ensure_dependencies_loaded()
        
        self.model = None
        self.device_mode = device
        self.device = get_recommended_device(device)
        self.lite = lite  # Â∞ÇÁî®„É¢„Éá„É´„Åã„Å©„ÅÜ„Åã„ÅÆ„Éï„É©„Ç∞
        self.load_model(model_path)
        
        # Specialized model class mapping (Anime NSFW Detection v4.0)
        self.specialized_class_mapping = {
            # Anime NSFW Detection v4.0„ÅÆ„ÇØ„É©„Çπ„Éû„ÉÉ„Éî„É≥„Ç∞
            # ÂÆüÈöõ„ÅÆ„ÇØ„É©„ÇπID„ÅØ‰ΩøÁî®„Åô„Çã„É¢„Éá„É´(.pt)„Å´„Çà„Å£„Å¶Áï∞„Å™„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çã„Åü„ÇÅ„ÄÅ
            # "all"„É¢„Éá„É´‰ΩøÁî®ÊôÇ„ÅÆ‰∏ÄËà¨ÁöÑ„Å™„Éû„ÉÉ„Éî„É≥„Ç∞„Çí‰ªÆÂÆö
            0: "male_genital",     # penis
            1: "female_genital",   # pussy/vagina  
            2: "anus",             # anus
            3: "testicles",        # testicles
            4: "nipples",          # nipples
            5: "breast"            # breast (if included)
        }
        
    def load_model(self, model_path: str):
        """Load YOLO model"""
        try:
            logger.info(f"Using {self.device.upper()} for inference")
            logger.info(f"Loading model from {model_path}")
            
            # Force PyTorch to not use weights_only mode for this specific load
            import os
            original_pytorch_weights_only = os.environ.get("PYTORCH_WEIGHTS_ONLY", None)
            os.environ["PYTORCH_WEIGHTS_ONLY"] = "false"
            
            try:
                # Initialize YOLOv8 model  
                _ensure_dependencies_loaded()
                if YOLO is None:
                    from ultralytics import YOLO as LocalYOLO
                    self.model = LocalYOLO(model_path)
                else:
                    self.model = YOLO(model_path)
            finally:
                # Restore original environment variable
                if original_pytorch_weights_only is None:
                    os.environ.pop("PYTORCH_WEIGHTS_ONLY", None)
                else:
                    os.environ["PYTORCH_WEIGHTS_ONLY"] = original_pytorch_weights_only
            
            # Move model to device
            if hasattr(self.model, 'to'):
                self.model.to(self.device)
                
            model_name = "anime_nsfw_v4" if self.lite else "genital_yolov8m"
            logger.info(f"Successfully loaded {model_name} model on {self.device}")
            
            if not self.lite:
                logger.warning("Note: Using generic demo detection model. Actual genital detection accuracy is limited.")
            else:
                logger.info("Using specialized genital detection model. High-precision body part detection available.")
                
        except Exception as e:
            logger.error(f"Failed to load model: {str(e)}")
            raise RuntimeError(f"Model loading failed: {str(e)}")
    
    def detect(self, image: Any, conf: float = 0.25, config=None) -> List[BBox]:
        """
        Detect objects in image using YOLO
        
        Args:
            image: Input image as numpy array (BGR format)
            conf: Confidence threshold (0.0 - 1.0)
            config: ProcessingConfig with part selection flags
            
        Returns:
            List of bounding boxes as (x1, y1, x2, y2) tuples for selected parts
        """
        # ‰æùÂ≠òÈñ¢‰øÇ„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åã„ÇânumpyÊìç‰Ωú„ÇíÂÆüË°å
        _ensure_dependencies_loaded()
        if self.model is None:
            raise RuntimeError("Model not loaded")
        
        if image is None or image.size == 0:
            logger.warning("Empty or invalid image provided")
            return []
        
        try:
            # Apply image preprocessing for better detection
            processed_image = self._preprocess_for_detection(image, config)
            
            # Run YOLO inference
            results = self.model(processed_image, conf=conf, verbose=False)
            
            if not results or len(results) == 0:
                logger.debug("No objects detected")
                return []
            
            result = results[0]
            if result.boxes is None or len(result.boxes) == 0:
                logger.debug("No bounding boxes found")
                return []
            
            bboxes = []
            
            if self.lite:
                # Â∞ÇÁî®„É¢„Éá„É´: Áõ¥Êé•ÈÉ®‰ΩçÊ§úÂá∫
                bboxes = self._process_specialized_detection(result, config)
            else:
                # Ê±éÁî®„É¢„Éá„É´: ‰∫∫Áâ©Ê§úÂá∫‚ÜíÈÉ®‰ΩçÊé®ÂÆö
                bboxes = self._process_person_detection(image, result, config)
            
            # Apply bbox expansion if specified in config
            # Note: Bbox expansion is now handled at mask level for better radial expansion
            # if config and hasattr(config, 'bbox_expansion') and config.bbox_expansion != 0:
            #     original_count = len(bboxes)
            #     bboxes = expand_bboxes(bboxes, config.bbox_expansion, image.shape[:2])
            #     if config.bbox_expansion > 0:
            #         logger.info(f"Expanded {original_count} bounding boxes by +{config.bbox_expansion}px for FANZA compliance")
            #     else:
            #         logger.info(f"Contracted {original_count} bounding boxes by {config.bbox_expansion}px")
            
            return bboxes
            
        except Exception as e:
            logger.error(f"Detection failed: {str(e)}")
            return []
    
    def _process_specialized_detection(self, result, config) -> List[BBox]:
        """Â∞ÇÁî®„É¢„Éá„É´„Å´„Çà„ÇãÁõ¥Êé•ÈÉ®‰ΩçÊ§úÂá∫"""
        bboxes = []
        
        for box in result.boxes:
            # Get bbox coordinates
            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
            cls_id = int(box.cls.cpu().numpy()[0])
            confidence = float(box.conf.cpu().numpy()[0])
            
            # „ÇØ„É©„ÇπID„ÇíÈÉ®‰ΩçÂêç„Å´„Éû„ÉÉ„Éî„É≥„Ç∞
            part_name = self.specialized_class_mapping.get(cls_id, "unknown")
            
            # Ë®≠ÂÆö„Å´Âü∫„Å•„ÅÑ„Å¶„Éï„Ç£„É´„Çø„É™„É≥„Ç∞
            if config and not self._is_part_selected(part_name, config):
                continue
                
            bboxes.append((x1, y1, x2, y2))
            logger.debug(f"{part_name} region added: ({x1}, {y1}, {x2}, {y2})")
            
        return bboxes
    
    def _process_person_detection(self, image: Any, result, config) -> List[BBox]:
        """Ê±éÁî®„É¢„Éá„É´„Å´„Çà„Çã‰∫∫Áâ©Ê§úÂá∫‚ÜíÈÉ®‰ΩçÊé®ÂÆö"""
        # Êó¢Â≠ò„ÅÆÂÆüË£Ö„Çí‰ΩøÁî®
        bboxes = []
        person_count = 0
        
        for box in result.boxes:
            cls_id = int(box.cls.cpu().numpy()[0])
            
            # Person class (class 0 in COCO)
            if cls_id == 0:
                person_count += 1
                # Get bbox coordinates
                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                person_bboxes = [(x1, y1, x2, y2)]
                
                # Êó¢Â≠ò„ÅÆÈÉ®‰ΩçÊé®ÂÆö„É≠„Ç∏„ÉÉ„ÇØ„Çí‰ΩøÁî®
                filtered_bboxes = self._filter_by_body_parts(image, person_bboxes, config)
                bboxes.extend(filtered_bboxes)
        
        if person_count == 0:
            logger.info("No person detected")
        else:
            logger.info(f"Extracted {len(bboxes)} region(s) from {person_count} person(s)")
            
        return bboxes
    
    def _is_part_selected(self, part_name: str, config) -> bool:
        """ÈÉ®‰Ωç„ÅåÈÅ∏Êäû„Åï„Çå„Å¶„ÅÑ„Çã„Åã„ÉÅ„Çß„ÉÉ„ÇØ"""
        if not config:
            return True
            
        mapping = {
            "female_genital": config.female_genital,
            "male_genital": config.male_genital,
            "anus": config.female_anal,  # „Ç¢„Éä„É´ÔºàÁî∑Â•≥ÂÖ±ÈÄöÔºâ
            "testicles": config.male_testis,  # Áùæ‰∏∏
            "nipples": False,  # ‰π≥È¶ñ„ÅØÁèæÂú®ÂØæË±°Â§ñ
            "breast": False   # ËÉ∏ÈÉ®„ÅØÂØæË±°Â§ñ
        }
        
        return mapping.get(part_name, False)
    
    def _filter_by_body_parts(self, image: Any, bboxes: List[BBox], config) -> List[BBox]:
        """
        Filter detected person boxes to focus on specific body parts
        
        Args:
            image: Input image
            bboxes: List of person bounding boxes
            config: Configuration with part selection flags
            
        Returns:
            List of filtered bounding boxes for specific body parts
        """
        if not config:
            return bboxes
        
        height, width = image.shape[:2]
        filtered_boxes = []
        
        for bbox in bboxes:
            x1, y1, x2, y2 = bbox
            box_width = x2 - x1
            box_height = y2 - y1
            center_x = (x1 + x2) // 2
            center_y = (y1 + y2) // 2
            
            # „Çà„ÇäÁèæÂÆüÁöÑ„Å™Ë∫´‰ΩìÊØî‰æã„Å´„Çà„ÇãÈÉ®‰ΩçÊé®ÂÆö
            # È†≠ÈÉ®„ÇíÈô§„ÅÑ„Åü‰ΩìÂππÈÉ®ÂàÜ„ÇíÂü∫Ê∫ñ„Å´„Åô„Çã
            torso_start_y = y1 + int(box_height * 0.15)  # È†≠ÈÉ®ÔºàÁ¥Ñ15%Ôºâ„ÇíÈô§„Åè
            torso_height = box_height - int(box_height * 0.15)
            
            # ÊÄßÂô®ÈÉ®ÂàÜ: ‰ΩìÂππ„ÅÆ60-80%‰ΩçÁΩÆÔºà„Å∏„Åù‰∏ã„Åã„ÇâËÇ°ÈñìÔºâ
            genital_y_start = torso_start_y + int(torso_height * 0.6)
            genital_y_end = torso_start_y + int(torso_height * 0.8)
            genital_x_start = center_x - int(box_width * 0.12)  # ‰∏≠Â§Æ„Åã„ÇâÂ∑¶Âè≥12%
            genital_x_end = center_x + int(box_width * 0.12)
            
            # „Ç¢„Éä„É´ÈÉ®ÂàÜ: ÊÄßÂô®„Çà„Çä„ÇÑ„ÇÑÂæåÊñπÔºà‰ªÆÊÉ≥ÁöÑ„Å´Â∞ë„Åó‰∏ãÔºâ
            anal_y_start = genital_y_start + int(box_height * 0.05)
            anal_y_end = genital_y_end + int(box_height * 0.05)
            anal_x_start = center_x - int(box_width * 0.08)   # „Çà„ÇäÁã≠„ÅÑÁØÑÂõ≤
            anal_x_end = center_x + int(box_width * 0.08)
            
            # Áùæ‰∏∏ÈÉ®ÂàÜ: ÊÄßÂô®„Çà„ÇäÂ∞ë„Åó‰∏ã
            testis_y_start = genital_y_end - int(box_height * 0.03)
            testis_y_end = genital_y_end + int(box_height * 0.05)
            testis_x_start = center_x - int(box_width * 0.1)
            testis_x_end = center_x + int(box_width * 0.1)
            
            # ÈÅ∏Êäû„Åï„Çå„ÅüÈÉ®‰Ωç„Å´Âü∫„Å•„ÅÑ„Å¶„Éú„ÉÉ„ÇØ„Çπ„ÇíÁîüÊàêÔºàÈáçË§áÊéíÈô§Ôºâ
            regions_to_add = []
            
            if config.female_genital or config.male_genital:
                genital_box = (
                    max(0, genital_x_start),
                    max(0, genital_y_start),
                    min(width, genital_x_end),
                    min(height, genital_y_end)
                )
                regions_to_add.append(("genital", genital_box))
            
            if config.female_anal:
                anal_box = (
                    max(0, anal_x_start),
                    max(0, anal_y_start),
                    min(width, anal_x_end),
                    min(height, anal_y_end)
                )
                regions_to_add.append(("anal", anal_box))
            
            if config.male_testis:
                testis_box = (
                    max(0, testis_x_start),
                    max(0, testis_y_start),
                    min(width, testis_x_end),
                    min(height, testis_y_end)
                )
                regions_to_add.append(("testis", testis_box))
            
            # ÈáçË§á„Åô„ÇãÈ†òÂüü„Çí„Éû„Éº„Ç∏„Åó„Å¶ËøΩÂä†
            for region_name, region_box in regions_to_add:
                filtered_boxes.append(region_box)
                logger.debug(f"{region_name} region added: {region_box}")
        
        logger.info(f"‰∫∫Áâ©{len(bboxes)}‰Ωì„Åã„Çâ{len(filtered_boxes)}ÂÄã„ÅÆÈÉ®‰ΩçÈ†òÂüü„ÇíÊäΩÂá∫")
        return filtered_boxes
    
    def _preprocess_for_detection(self, image: Any, config=None) -> Any:
        """
        Return original image without preprocessing
        
        Args:
            image: Input image as numpy array (BGR format)
            config: ProcessingConfig (not used)
            
        Returns:
            Original image unchanged
        """
        return image
    
    def detect_batch(self, images: List[Any], conf: float = 0.25, config=None) -> List[List[BBox]]:
        """
        Detect genital regions in multiple images
        
        Args:
            images: List of images as numpy arrays
            conf: Confidence threshold
            config: ProcessingConfig with part selection flags
            
        Returns:
            List of bounding box lists for each image
        """
        results = []
        for i, image in enumerate(images):
            try:
                bboxes = self.detect(image, conf, config)
                results.append(bboxes)
                logger.debug(f"Processed image {i+1}/{len(images)}: {len(bboxes)} detections")
            except Exception as e:
                logger.error(f"Failed to process image {i+1}: {str(e)}")
                results.append([])
        
        return results
    
    def visualize_detections(self, image: Any, bboxes_with_class: List[BBoxWithClass]) -> Any:
        """
        Visualize detection results with colored bounding boxes
        
        Args:
            image: Original image
            bboxes_with_class: List of bounding boxes with class information
            
        Returns:
            Image with bounding boxes drawn
        """
        if not bboxes_with_class:
            return image.copy()
        
        vis_image = image.copy()
        
        # Define colors for each model class
        colors = {
            'penis': (0, 0, 255),           # Red
            'labia_minora': (255, 0, 255),  # Magenta - Â∞èÈô∞Âîá
            'labia_majora': (255, 100, 255), # Light Magenta - Â§ßÈô∞Âîá
            'pussy': (255, 0, 255),         # Magenta - ‰∫íÊèõÊÄßÁ∂≠ÊåÅ
            'testicles': (0, 255, 255),     # Cyan
            'anus': (0, 165, 255),          # Orange
            'nipples': (255, 255, 0),       # Yellow
            'x-ray': (128, 0, 128),         # Purple
            'cross-section': (0, 128, 255), # Orange-red
            'all': (255, 0, 0)              # Blue
        }
        
        for bbox_with_class in bboxes_with_class:
            x1, y1, x2, y2, class_name, source = bbox_with_class
            
            # Get color for this class
            color = colors.get(class_name, (0, 255, 0))  # Default green
            
            # Draw bounding box
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 2)
            
            # Draw class label with source information
            label = f"{class_name} ({source})"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
            cv2.rectangle(vis_image, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), color, -1)
            cv2.putText(vis_image, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return vis_image
    
    def get_model_info(self) -> dict:
        """Get information about the loaded model"""
        return {
            "model_type": "anime_nsfw_v4" if self.lite else "genital_yolov8m",
            "device": self.device,
            "lite_mode": self.lite,
            "loaded": self.model is not None
        }
    
    def switch_model(self, use_lite: bool):
        """Switch between lite and full model"""
        if use_lite != self.lite:
            logger.info(f"Switching to {'lite' if use_lite else 'full'} model")
            self.lite = use_lite
            self.load_model(self.model.model.path)

# Factory function for easy instantiation
def create_detector(model_path: str, device: str = "auto", lite: bool = False) -> GenitalDetector:
    """
    Create and return a configured GenitalDetector instance
    
    Args:
        model_path: Path to YOLO model
        device: Device for inference ('cpu', 'cuda', or 'auto')
        lite: Whether using the lite model
        
    Returns:
        Configured GenitalDetector instance
    """
    return GenitalDetector(model_path, device, lite)

class MultiModelDetector:
    """Multiple specialized model detector for Anime NSFW Detection v4.0 with NudeNet integration"""
    
    def __init__(self, config, device: str = "auto"):
        """
        Initialize multi-model detector
        
        Args:
            config: ProcessingConfig with selected_models dictionary
            device: Device for inference ('cpu', 'cuda', or 'auto')
        """
        self.config = config
        self.device_mode = device
        self.device = get_recommended_device(device)
        self.models = {}  # Dictionary to hold loaded models
        
        # Initialize NudeNet detector
        self.nudenet_detector = None
        self.hybrid_detector = None
        
        self.load_selected_models()
        self._initialize_nudenet()
        self._setup_hybrid_detector()
        
    def load_selected_models(self):
        """Load only the selected model files"""
        from auto_mosaic.src.downloader import downloader
        
        logger.info(f"Using {self.device.upper()} for inference")
        
        # „Ç§„É©„Çπ„ÉàÂ∞ÇÁî®„É¢„Éá„É´„ÅßÊúâÂäπ„Å™„É¢„Éá„É´„ÅÆ„É™„Çπ„Éà
        valid_anime_models = ["penis", "labia_minora", "pussy", "testicles", "anus", "nipples", "x-ray", "cross-section", "all"]
        
        selected_count = 0
        
        # Ê®ôÊ∫ñ„É¢„Éá„É´„ÅÆË™≠„ÅøËæº„Åø
        for model_key, is_selected in self.config.selected_models.items():
            if is_selected:
                # „Ç§„É©„Çπ„ÉàÂ∞ÇÁî®„É¢„Éá„É´„Åß„Çµ„Éù„Éº„Éà„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑ„É¢„Éá„É´„ÅØ„Çπ„Ç≠„ÉÉ„Éó
                if model_key not in valid_anime_models:
                    logger.info(f"Skipping {model_key} model (not supported by „Ç§„É©„Çπ„ÉàÂ∞ÇÁî®„É¢„Éá„É´)")
                    continue
                    
                model_path = downloader.get_model_path("anime_nsfw_v4", model_key)
                if model_path and model_path.exists():
                    try:
                        logger.info(f"Loading {model_key} model from {model_path}")
                        
                        # Force PyTorch to not use weights_only mode for this specific load
                        import os
                        original_pytorch_weights_only = os.environ.get("PYTORCH_WEIGHTS_ONLY", None)
                        os.environ["PYTORCH_WEIGHTS_ONLY"] = "false"
                        
                        try:
                            # ‰æùÂ≠òÈñ¢‰øÇ„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åã„ÇâYOLO„Çí‰ΩøÁî®
                            _ensure_dependencies_loaded()
                            if YOLO is None:
                                from ultralytics import YOLO as LocalYOLO
                                model = LocalYOLO(str(model_path))
                            else:
                                model = YOLO(str(model_path))
                        finally:
                            # Restore original environment variable
                            if original_pytorch_weights_only is None:
                                os.environ.pop("PYTORCH_WEIGHTS_ONLY", None)
                            else:
                                os.environ["PYTORCH_WEIGHTS_ONLY"] = original_pytorch_weights_only
                        
                        # Move model to device
                        if hasattr(model, 'to'):
                            model.to(self.device)
                            
                        self.models[model_key] = model
                        selected_count += 1
                        logger.info(f"Successfully loaded {model_key} model")
                        
                    except Exception as e:
                        logger.error(f"Failed to load {model_key} model: {str(e)}")
                else:
                    logger.warning(f"Model file not found for {model_key}: {model_path}")
        
        # „Ç´„Çπ„Çø„É†„É¢„Éá„É´„ÅÆË™≠„ÅøËæº„Åø
        if hasattr(self.config, 'use_custom_models') and self.config.use_custom_models:
            selected_count += self._load_custom_models()
        
        if selected_count == 0:
            # „Çà„ÇäË¶™Âàá„Å™„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÊèê‰æõ
            models_dir = Path(downloader.models_dir)
            anime_nsfw_dir = models_dir / "anime_nsfw_v4"
            
            error_msg = (
                "‚ùå Ê§úÂá∫Áî®„É¢„Éá„É´„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ\n\n"
                f"„ÄêÂøÖË¶Å„Å™„Éï„Ç°„Ç§„É´„Äë\n"
                f"„ÉªAnime NSFW Detection v4.0 „É¢„Éá„É´„Éï„Ç°„Ç§„É´\n"
                f"„ÉªÈÖçÁΩÆÂÖà: {anime_nsfw_dir}\n\n"
                f"„ÄêËß£Ê±∫ÊñπÊ≥ï„Äë\n"
                f"1. CivitAI„Åã„Çâ„ÄåAnime NSFW Detection v4.0„Äç„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\n"
                f"2. ZIP„Éï„Ç°„Ç§„É´„ÇíÂ±ïÈñã„Åó„Å¶‰∏äË®ò„Éï„Ç©„É´„ÉÄ„Å´ÈÖçÁΩÆ\n"
                f"3. „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÇíÂÜçËµ∑Âãï\n\n"
                f"„Äê„Ç´„Çπ„Çø„É†„É¢„Éá„É´„Äë\n"
                f"„Åæ„Åü„ÅØ„ÄÅË®≠ÂÆö > „Ç´„Çπ„Çø„É†„É¢„Éá„É´ „Åã„Çâ‰ªªÊÑè„ÅÆ.pt„Éï„Ç°„Ç§„É´„ÇíÊåáÂÆö\n\n"
                f"„Äê„Éï„Ç©„É´„ÉÄ„ÇíÈñã„Åè„Äë\n"
                f"Ë®≠ÂÆö > „É¢„Éá„É´ÁÆ°ÁêÜ > „Éï„Ç©„É´„ÉÄ„ÇíÈñã„Åè „Åã„ÇâÈÖçÁΩÆÂÖà„ÇíÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ"
            )
            
            logger.error("No valid detection models found")
            logger.info(f"Models directory: {models_dir}")
            logger.info(f"Expected anime_nsfw_v4 directory: {anime_nsfw_dir}")
            logger.info(f"Directory exists: {anime_nsfw_dir.exists()}")
            
            if anime_nsfw_dir.exists():
                files = list(anime_nsfw_dir.glob("*.pt"))
                logger.info(f"Found .pt files: {len(files)}")
                for file in files:
                    logger.info(f"  - {file.name}")
            
            raise RuntimeError(error_msg)
            
        logger.info(f"Loaded {selected_count} specialized NSFW detection models. High-precision part detection available.")
        
    def _load_custom_models(self):
        """„Ç´„Çπ„Çø„É†„É¢„Éá„É´„ÇíË™≠„ÅøËæº„ÇÄ"""
        if not hasattr(self.config, 'custom_models'):
            return 0
            
        loaded_count = 0
        for model_name, model_config in self.config.custom_models.items():
            if not model_config.get('enabled', False):
                continue
                
            model_path = Path(model_config.get('path', ''))
            if not model_path.exists():
                logger.warning(f"Custom model file not found: {model_path}")
                continue
                
            try:
                logger.info(f"Loading custom model '{model_name}' from {model_path}")
                
                # Force PyTorch to not use weights_only mode for this specific load
                import os
                original_pytorch_weights_only = os.environ.get("PYTORCH_WEIGHTS_ONLY", None)
                os.environ["PYTORCH_WEIGHTS_ONLY"] = "false"
                
                try:
                    # ‰æùÂ≠òÈñ¢‰øÇ„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åã„ÇâYOLO„Çí‰ΩøÁî®
                    _ensure_dependencies_loaded()
                    if YOLO is None:
                        from ultralytics import YOLO as LocalYOLO
                        model = LocalYOLO(str(model_path))
                    else:
                        model = YOLO(str(model_path))
                finally:
                    # Restore original environment variable
                    if original_pytorch_weights_only is None:
                        os.environ.pop("PYTORCH_WEIGHTS_ONLY", None)
                    else:
                        os.environ["PYTORCH_WEIGHTS_ONLY"] = original_pytorch_weights_only
                
                # Move model to device
                if hasattr(model, 'to'):
                    model.to(self.device)
                    
                # „Ç´„Çπ„Çø„É†„É¢„Éá„É´Áî®„ÅÆ„Ç≠„Éº„Åß‰øùÂ≠ò
                custom_key = f"custom_{model_name}"
                self.models[custom_key] = model
                
                # „ÇØ„É©„Çπ„Éû„ÉÉ„Éî„É≥„Ç∞„Çí‰øùÂ≠ò
                class_mapping = model_config.get('class_mapping', {})
                if class_mapping:
                    self.custom_class_mappings = getattr(self, 'custom_class_mappings', {})
                    self.custom_class_mappings[custom_key] = class_mapping
                
                loaded_count += 1
                logger.info(f"Successfully loaded custom model '{model_name}'")
                
            except Exception as e:
                logger.error(f"Failed to load custom model '{model_name}': {str(e)}")
        
        return loaded_count
    
    def _initialize_nudenet(self):
        """Initialize NudeNet detector if enabled"""
        logger.info(f"[DEBUG] Checking NudeNet initialization - config has use_nudenet: {hasattr(self.config, 'use_nudenet')}")
        if hasattr(self.config, 'use_nudenet'):
            logger.info(f"[DEBUG] use_nudenet value: {self.config.use_nudenet}")
        
        if hasattr(self.config, 'use_nudenet') and self.config.use_nudenet:
            logger.info("[DEBUG] Attempting to initialize ÂÆüÂÜôÂ∞ÇÁî®„É¢„Éá„É´...")
            try:
                from auto_mosaic.src.nudenet_detector import NudeNetDetector
                self.nudenet_detector = NudeNetDetector(device=self.device_mode)
                if self.nudenet_detector.initialize():
                    logger.info("‚úÖ ÂÆüÂÜôÂ∞ÇÁî®„É¢„Éá„É´ initialized and ready")
                else:
                    self.nudenet_detector = None
                    logger.warning("‚ùå Failed to initialize ÂÆüÂÜôÂ∞ÇÁî®„É¢„Éá„É´")
            except ImportError as e:
                import sys
                if getattr(sys, 'frozen', False):
                    logger.warning(f"‚ùå ÂÆüÂÜôÂ∞ÇÁî®„É¢„Éá„É´ not available in executable version. Import error: {e}")
                    logger.warning("NudeNet requires additional DLL setup for executable version.")
                    logger.info("üîÑ Application will continue with anime-only detection models")
                else:
                    logger.warning("‚ùå ÂÆüÂÜôÂ∞ÇÁî®„É¢„Éá„É´ not available. Please install with: pip install nudenet")
                self.nudenet_detector = None
            except Exception as e:
                import sys
                if getattr(sys, 'frozen', False) and "DLL" in str(e):
                    logger.warning(f"‚ùå NudeNet DLL initialization failed in executable: {e}")
                    logger.info("üîÑ This is expected in some exe environments - continuing with anime models only")
                else:
                    logger.error(f"‚ùå Error initializing ÂÆüÂÜôÂ∞ÇÁî®„É¢„Éá„É´: {e}")
                    import traceback
                    logger.error(f"Full traceback: {traceback.format_exc()}")
                self.nudenet_detector = None
        else:
            logger.info("[DEBUG] ÂÆüÂÜôÂ∞ÇÁî®„É¢„Éá„É´ initialization skipped (not enabled in config)")
    
    def _setup_hybrid_detector(self):
        """Setup hybrid detector that combines „Ç§„É©„Çπ„ÉàÂ∞ÇÁî®„É¢„Éá„É´ and ÂÆüÂÜôÂ∞ÇÁî®„É¢„Éá„É´"""
        logger.info(f"[DEBUG] Setting up hybrid detector - anime_models: {len(self.models)}, nudenet: {self.nudenet_detector is not None}")
        try:
            from auto_mosaic.src.nudenet_detector import HybridDetector
            self.hybrid_detector = HybridDetector(
                anime_detector=self if self.models else None,
                nudenet_detector=self.nudenet_detector
            )
            logger.info("‚úÖ Hybrid detector setup complete")
        except Exception as e:
            logger.error(f"‚ùå Failed to setup hybrid detector: {e}")
            self.hybrid_detector = None
    
    def detect(self, image: Any, conf: float = 0.25, config=None) -> List[BBoxWithClass]:
        """
        Detect objects using multiple specialized models and/or NudeNet
        
        Args:
            image: Input image as numpy array (BGR format)
            conf: Confidence threshold (0.0 - 1.0)
            config: ProcessingConfig with detection settings
            
        Returns:
            List of bounding boxes with class information from all selected detectors
        """
        if image is None or image.size == 0:
            logger.warning("Empty or invalid image provided")
            return []
        
        # Get detector settings from config
        use_anime = getattr(config, 'use_anime_detector', True) if config else True
        use_nudenet = getattr(config, 'use_nudenet', True) if config else False
        
        # Use hybrid detector if available
        if self.hybrid_detector:
            logger.info(f"Using hybrid detector: „Ç§„É©„Çπ„ÉàÂ∞ÇÁî®„É¢„Éá„É´={use_anime}, ÂÆüÂÜôÂ∞ÇÁî®„É¢„Éá„É´={use_nudenet}")
            return self._detect_with_hybrid(image, conf, use_anime, use_nudenet, config)
        
        # Fall back to original anime_nsfw_v4 only detection
        if use_anime and self.models:
            logger.info("Falling back to „Ç§„É©„Çπ„ÉàÂ∞ÇÁî®„É¢„Éá„É´ only detection (hybrid detector not available)")
            return self._detect_anime_only(image, conf, config)
        
        logger.warning("No detectors available")
        return []
    
    def _detect_with_hybrid(self, image: Any, conf: float, use_anime: bool, use_nudenet: bool, config=None) -> List[BBoxWithClass]:
        """Use hybrid detector for combined detection"""
        try:
            combined_results = self.hybrid_detector.detect_image(
                image, 
                confidence=conf, 
                use_anime=use_anime, 
                use_nudenet=use_nudenet,
                config=config
            )
            
            # Convert to BBoxWithClass format
            all_bboxes_with_class = []
            for part_name, detections in combined_results.items():
                for detection in detections:
                    x1, y1, x2, y2, class_name, source = detection
                    all_bboxes_with_class.append((x1, y1, x2, y2, class_name, source))
            
            total_detections = len(all_bboxes_with_class)
            if total_detections > 0:
                parts_summary = ", ".join([f"{part}:{len(dets)} regions" for part, dets in combined_results.items() if dets])
                logger.info(f"[Hybrid Detection] Total: {total_detections} regions ({parts_summary})")
            else:
                logger.info("[Hybrid Detection] No target regions detected")
            
            return all_bboxes_with_class
            
        except Exception as e:
            logger.error(f"Hybrid detection failed: {e}")
            return []
    
    def _detect_anime_only(self, image: Any, conf: float, config=None) -> List[BBoxWithClass]:
        """Original „Ç§„É©„Çπ„ÉàÂ∞ÇÁî®„É¢„Éá„É´ only detection"""
        if not self.models:
            logger.warning("No „Ç§„É©„Çπ„ÉàÂ∞ÇÁî®„É¢„Éá„É´ loaded")
            return []
        
        all_bboxes_with_class = []
        detected_parts = {}
        detection_times = {}
        
        try:
            total_detect_start = time.time()
            
            # Run inference with each selected model
            for model_key, model in self.models.items():
                # „Ç´„Çπ„Çø„É†„É¢„Éá„É´„ÅÆÂ†¥Âêà„ÅÆÂá¶ÁêÜ
                if model_key.startswith("custom_"):
                    if config and hasattr(config, 'use_custom_models') and not config.use_custom_models:
                        logger.info(f"Skipping {model_key} model (custom models disabled)")
                        continue
                    # „Ç´„Çπ„Çø„É†„É¢„Éá„É´„ÅØÂ∏∏„Å´ÊúâÂäπ„Å®„Åó„Å¶Êâ±„ÅÜÔºàÂÄãÂà•„ÅÆÁÑ°ÂäπÂåñ„ÅØË®≠ÂÆö„É¨„Éô„É´„ÅßÁÆ°ÁêÜÔºâ
                else:
                    # Ê®ôÊ∫ñ„É¢„Éá„É´„ÅÆ„É¶„Éº„Ç∂„ÉºÈÅ∏Êäû„Çí„ÉÅ„Çß„ÉÉ„ÇØ
                    if config and hasattr(config, 'selected_models'):
                        if not config.selected_models.get(model_key, False):
                            logger.info(f"Skipping {model_key} model (not selected by user)")
                            continue
                
                model_start = time.time()
                
                results = model(image, conf=conf, verbose=False)
                
                model_time = time.time() - model_start
                detection_times[model_key] = model_time
                logger.info(f"  [{model_key} Model] Inference time: {model_time:.2f}s")
                
                if results and len(results) > 0:
                    result = results[0]
                    if result.boxes is not None and len(result.boxes) > 0:
                        model_bboxes = []
                        for box in result.boxes:
                            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                            confidence = float(box.conf.cpu().numpy()[0])
                            
                            # „Ç´„Çπ„Çø„É†„É¢„Éá„É´„ÅÆÂ†¥Âêà„ÅØ„ÇØ„É©„ÇπÊÉÖÂ†±„Çí„Éû„ÉÉ„Éî„É≥„Ç∞
                            if model_key.startswith("custom_"):
                                class_id = int(box.cls.cpu().numpy()[0])
                                custom_class_mappings = getattr(self, 'custom_class_mappings', {})
                                class_mapping = custom_class_mappings.get(model_key, {})
                                class_name = class_mapping.get(class_id, f"class_{class_id}")
                                source = 'CU'  # Custom model source
                            else:
                                class_name = model_key
                                source = 'IL'  # Illustration model source
                            
                            # „ÇØ„É©„ÇπÊÉÖÂ†±„Å®„ÇΩ„Éº„ÇπÊÉÖÂ†±„ÇíËøΩÂä†„Åó„Å¶BBoxWithClass„Å®„Åó„Å¶‰øùÂ≠ò
                            bbox_with_class = (x1, y1, x2, y2, class_name, source)
                            all_bboxes_with_class.append(bbox_with_class)
                            model_bboxes.append((x1, y1, x2, y2))
                            logger.debug(f"{model_key} region added: ({x1}, {y1}, {x2}, {y2}) [conf: {confidence:.3f}, class: {class_name}]")
                        
                        detected_parts[model_key] = len(model_bboxes)
            
            total_detect_time = time.time() - total_detect_start
            
            # Log output
            times_str = ", ".join([f"{k}:{v:.1f}s" for k, v in detection_times.items()])
            logger.info(f"[All Models Detection] Time: {total_detect_time:.2f}s ({times_str})")
            
            if detected_parts:
                parts_str = ", ".join([f"{k}:{v} regions" for k, v in detected_parts.items()])
                logger.info(f"Detected parts: {parts_str} (total: {len(all_bboxes_with_class)} regions)")
            else:
                logger.info("No target regions detected")
            
            return all_bboxes_with_class
            
        except Exception as e:
            logger.error(f"Multi-model detection failed: {str(e)}")
            return []
    
    def detect_image(self, image: Any, confidence: float = 0.25, config=None) -> Dict[str, List]:
        """
        Wrapper method for compatibility with hybrid detector interface
        
        Args:
            image: Input image
            confidence: Confidence threshold
            config: Configuration object with user settings
            
        Returns:
            Dictionary with part names as keys and bounding boxes as values
        """
        bboxes = self._detect_anime_only(image, confidence, config)
        
        # Convert to dictionary format
        results = {}
        for bbox in bboxes:
            x1, y1, x2, y2, class_name, source = bbox
            if class_name not in results:
                results[class_name] = []
            results[class_name].append((x1, y1, x2, y2, class_name, source))
        
        return results
    
    def get_model_info(self) -> dict:
        """Get information about loaded models"""
        return {
            "model_type": "anime_nsfw_v4_multi",
            "device": self.device,
            "loaded_models": list(self.models.keys()),
            "model_count": len(self.models)
        }
    
    def visualize_detections(self, image: Any, bboxes_with_class: List[BBoxWithClass]) -> Any:
        """
        Visualize detection results with colored bounding boxes
        
        Args:
            image: Original image
            bboxes_with_class: List of bounding boxes with class information
            
        Returns:
            Image with bounding boxes drawn
        """
        if not bboxes_with_class:
            return image.copy()
        
        vis_image = image.copy()
        
        # Define colors for each model class (both anime_nsfw_v4 and NudeNet)
        colors = {
            # anime_nsfw_v4 colors
            'penis': (0, 0, 255),           # Red
            'labia_minora': (255, 0, 255),  # Magenta - Â∞èÈô∞Âîá
            'labia_majora': (255, 100, 255), # Light Magenta - Â§ßÈô∞Âîá
            'pussy': (255, 0, 255),         # Magenta - ‰∫íÊèõÊÄßÁ∂≠ÊåÅ
            'testicles': (0, 255, 255),     # Cyan
            'anus': (0, 165, 255),          # Orange
            'nipples': (255, 255, 0),       # Yellow
            'x-ray': (128, 0, 128),         # Purple
            'cross-section': (0, 128, 255), # Orange-red
            'all': (255, 0, 0),             # Blue
            
            # NudeNet colors (different shades for distinction)
            'male_genital': (0, 0, 200),      # Dark Red
            'female_genital': (200, 0, 200),  # Dark Magenta
            'buttocks': (0, 200, 200),        # Dark Cyan
            'female_breast': (200, 200, 0),   # Dark Yellow
            'male_breast': (150, 150, 0),     # Olive
            'belly': (100, 100, 255),         # Light Blue
            'feet': (255, 100, 100),          # Light Red
            'armpits': (100, 255, 100),       # Light Green
            'face': (255, 200, 100),          # Light Orange
        }
        
        for bbox_with_class in bboxes_with_class:
            x1, y1, x2, y2, class_name, source = bbox_with_class
            
            # Get color for this class
            color = colors.get(class_name, (0, 255, 0))  # Default green
            
            # Draw bounding box
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 2)
            
            # Draw class label with source indicator
            label = f"{class_name} ({source})"
                
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
            cv2.rectangle(vis_image, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), color, -1)
            cv2.putText(vis_image, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return vis_image 